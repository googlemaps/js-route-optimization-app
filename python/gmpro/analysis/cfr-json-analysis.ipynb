{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_P09hNJhnPA"
      },
      "source": [
        "# CFR JSON request/response analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrvDGML6NlWW"
      },
      "source": [
        "## License\n",
        "\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "   https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZIL_uwHMAsg"
      },
      "source": [
        "## Using the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvdsDlH_R6TH"
      },
      "source": [
        "### Prerequisities\n",
        "\n",
        "If you're not familiar with Colab notebooks, check out the\n",
        "[Welcome to Colaboratory](https://colab.research.google.com/notebooks/intro.ipynb)\n",
        "notebook first for a tutorial.\n",
        "\n",
        "To run the cells in the notebook, you need a runtime:\n",
        "\n",
        "*   We regularly test the notebook with the public hosted runtime. This should\n",
        "    be sufficient for experiments and to analyze smaller scenarios.\n",
        "*   If the hosted runtime is too slow or you need to process large amount of\n",
        "    data,\n",
        "    [running a local runtime](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "    might be a better option. To use a local runtime with this notebook, start\n",
        "    the local runtime with `sudo docker run -p 127.0.0.1:9000:8080 -e\n",
        "    COLAB_KERNEL_MANAGER_PROXY_PORT=9000\n",
        "    us-docker.pkg.dev/colab-images/public/runtime` and then follow the rest of\n",
        "    the instructions from the\n",
        "    [local runtime guide](https://research.google.com/colaboratory/local-runtimes.html).\n",
        "    As of 2023-10-23, using the `COLAB_KERNEL_MANAGER_PROXY_PORT` option is\n",
        "    needed to make file upload work correctly.\n",
        "\n",
        "### How to use the colab\n",
        "\n",
        "1.  Once you're connected to a runtime, the first setp is to run the cells in\n",
        "    the \"Imports, helper functions\" section to initialize the notebook. You can\n",
        "    re-run the cell \"Define helper functions, ...\" at any time to quickly remove\n",
        "    all loaded scenarios from the notebook.\n",
        "\n",
        "2.  Once the notebook is initialized, you will be able to add CFR scenarios and\n",
        "    solutions to the notebook to analyze them. The easiest way is to upload\n",
        "    either ZIP files from the fleet routing app or the scenario/solution JSON\n",
        "    file pairs through the form in the section\n",
        "    [Upload scenarios and solutions](#scrollTo=G6mXfeDxgA4M&line=1&uniqifier=1).\n",
        "\n",
        "3.  Now you have data to analyze. Run any other cell in the notebook to walk\n",
        "    through the data.\n",
        "\n",
        "### Don't panic!\n",
        "\n",
        "If you have any questions or run into issues with using the colab, contact\n",
        "ondrasej at google dot com.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH66ug0igXSc"
      },
      "source": [
        "## Imports, helper functions (run these first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vG20dqFKAPpE"
      },
      "outputs": [],
      "source": [
        "# @title Import everything (run this once)\n",
        "\n",
        "import collections\n",
        "from collections.abc import Callable, Iterable, Mapping, Sequence, Set\n",
        "import dataclasses\n",
        "import datetime\n",
        "import functools\n",
        "import glob\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from typing import Any\n",
        "import zipfile\n",
        "\n",
        "from google.colab import data_table\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "from IPython import display\n",
        "import ipywidgets\n",
        "import pandas as pd\n",
        "\n",
        "# # Clone the CFR library from GitHub, and import from there.\n",
        "!git clone https://github.com/google/cfr\n",
        "from cfr.python.gmpro import utils\n",
        "from cfr.python.gmpro.analysis import analysis\n",
        "from cfr.python.gmpro.json import cfr_json\n",
        "from cfr.python.gmpro.json import human_readable\n",
        "from cfr.python.gmpro.two_step_routing import two_step_routing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ukVuR1MgMp4y"
      },
      "outputs": [],
      "source": [
        "# @title Define helper functions, reset data structures\n",
        "\n",
        "\n",
        "# Increase the default limit on the number of rows in a DataTable. The default\n",
        "# limit is 20k, and it is not quite enough for our use cases.\n",
        "data_table.DataTable.max_rows = 250000  # @param{type: 'number'}\n",
        "data_table.DataTable.num_rows_per_page = 50  # @param{type: 'number'}\n",
        "data_table.DataTable.max_columns = 30  # @param{type: 'number'}\n",
        "\n",
        "# TODO(ondrasej): Consider moving this to a separate library that can be tested\n",
        "# with normal unit tests.\n",
        "\n",
        "\n",
        "# The effective maximal and minimal datetime values in UTC. The `min` and `max`\n",
        "# defined on the datetime class are naive datetimes and they can't be directly\n",
        "# compared with the timestamps including a time zone that we use in the code.\n",
        "_DATETIME_MIN_UTC = datetime.datetime.min.replace(tzinfo=datetime.timezone.utc)\n",
        "_DATETIME_MAX_UTC = datetime.datetime.max.replace(tzinfo=datetime.timezone.utc)\n",
        "\n",
        "\n",
        "# The scenario data used for the analyses in the notebook.\n",
        "_scenarios = {}\n",
        "\n",
        "\n",
        "def add_scenario_and_solution_from_bytes(\n",
        "    name: str,\n",
        "    scenario_bytes: bytes,\n",
        "    solution_bytes: bytes,\n",
        "    parking_bytes: bytes | None,\n",
        ") -> analysis.Scenario:\n",
        "  \"\"\"Adds a scenario-solution pair to the collection of analyzed scenarios.\n",
        "\n",
        "  Loads the scenario and solution data by treating `scenario_bytes` and\n",
        "  `solution_bytes` as encoded JSON data.\n",
        "\n",
        "  Args:\n",
        "    name: The name of the new scenario. If a scenario of this name already\n",
        "      exists, it is overwritten.\n",
        "    scenario_bytes: The serialized JSON data of the scenario.\n",
        "    solution_bytes: The serialized JSON data of the solution.\n",
        "    parking_bytes: The serialized JSON data for the parking location.\n",
        "\n",
        "  Returns:\n",
        "    The added scenario.\n",
        "  \"\"\"\n",
        "  # Lean on the automatic encoding detection in the JSON parser.\n",
        "  scenario_json = json.load(io.BytesIO(scenario_bytes))\n",
        "  solution_json = json.load(io.BytesIO(solution_bytes))\n",
        "  parking_json = (\n",
        "      json.load(io.BytesIO(parking_bytes))\n",
        "      if parking_bytes is not None\n",
        "      else None\n",
        "  )\n",
        "\n",
        "  scenario = analysis.Scenario(\n",
        "      name=name,\n",
        "      scenario=scenario_json,\n",
        "      solution=solution_json,\n",
        "      parking_json=parking_json,\n",
        "  )\n",
        "  _scenarios[name] = scenario\n",
        "  return scenario\n",
        "\n",
        "\n",
        "def add_scenario_and_solution_from_file(\n",
        "    name: str, scenario_file: str, solution_file: str, parking_file: str | None\n",
        ") -> analysis.Scenario:\n",
        "  \"\"\"Adds a scenario-solution pair to the collection of analyzed scenarios.\n",
        "\n",
        "  Assumes that `scenario_file` and `solution_file` are two JSON files that are\n",
        "  accessible through the local file system and that contain the data in the JSON\n",
        "  format. Loads and parses the contents of the two files and adds them to the\n",
        "  scenario list.\n",
        "\n",
        "  Args:\n",
        "    name: The name of the new scenario. If a scenario of this name already\n",
        "      exists, it is overwritten.\n",
        "    scenario_file: The file name of the scenario.\n",
        "    solution_file: The file name of the solution.\n",
        "\n",
        "  Returns:\n",
        "    The added scenario.\n",
        "  \"\"\"\n",
        "  with open(scenario_file, \"rt\", encoding=\"utf-8\") as f:\n",
        "    scenario_json = json.load(f)\n",
        "  with open(solution_file, \"rt\", encoding=\"utf-8\") as f:\n",
        "    solution_json = json.load(f)\n",
        "  parking_json = None\n",
        "  if parking_file:  # Covers both an empty string and None.\n",
        "    with open(parking_file, \"rt\", encoding=\"utf-8\") as f:\n",
        "      parking_json = json.load(f)\n",
        "  else:\n",
        "    parking_file = None\n",
        "  scenario = analysis.Scenario(\n",
        "      name=name,\n",
        "      scenario=scenario_json,\n",
        "      solution=solution_json,\n",
        "      parking_json=parking_json,\n",
        "  )\n",
        "  _scenarios[name] = scenario\n",
        "  return scenario\n",
        "\n",
        "\n",
        "def all_scenarios():\n",
        "  \"\"\"Returns the list of all scenario names, in the lexicographic order.\"\"\"\n",
        "  return sorted(_scenarios.values(), key=lambda scenario: scenario.name)\n",
        "\n",
        "\n",
        "def dataframe_from_all_scenarios(\n",
        "    row_callback: Callable[\n",
        "        [analysis.Scenario], dict[str, Any] | list[dict[str, Any]]\n",
        "    ]\n",
        "):\n",
        "  \"\"\"Creates a data frame by calling `row_callback` for each scenario.\n",
        "\n",
        "  Expects that `row_callback` returns either a dict or a list of dicts. When it\n",
        "  returns a dict, it is treated as a row in the data frame. When it returns a\n",
        "  list, each element of the list is treated as a separate row.\n",
        "\n",
        "  Creates a data frame that contains the data returned for all scenarios,\n",
        "  indexed by the scenario name.\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  scenarios = all_scenarios()\n",
        "  index = []\n",
        "  for scenario in scenarios:\n",
        "    scenario_data = row_callback(scenario)\n",
        "    if isinstance(scenario_data, dict):\n",
        "      data.append(scenario_data)\n",
        "      index.append(scenario.name)\n",
        "    elif isinstance(scenario_data, list):\n",
        "      data.extend(scenario_data)\n",
        "      for _ in scenario_data:\n",
        "        index.append(scenario.name)\n",
        "  return pd.DataFrame(data, index=index)\n",
        "\n",
        "\n",
        "def show_table_from_all_scenarios(\n",
        "    row_callback: Callable[\n",
        "        [analysis.Scenario], dict[str, Any] | list[dict[str, Any]]\n",
        "    ]\n",
        "):\n",
        "  display.display(\n",
        "      data_table.DataTable(\n",
        "          dataframe_from_all_scenarios(row_callback).fillna(\"\")\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "def get_glob_substitutions(pattern: str, filename: str) -> tuple[str]:\n",
        "  \"\"\"Returns substitutions to wildcards from `pattern` in `filename`.\n",
        "\n",
        "  Assumes that `filename` is matched by the glob pattern `pattern`. Returns a\n",
        "  sequence of substitutions to all wildcards in pattern that are needed to match\n",
        "  `filename`. The returned sequence has one element per wildcard, and they are\n",
        "  ordered by the appearance of the wildcard in the pattern.\n",
        "\n",
        "  At this moment, only `*` is supported.\n",
        "\n",
        "  Returns:\n",
        "    A sequence that contains the substitutions.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: When there is a problem with extracting the substitutions. This\n",
        "      can happen when: `filename` does not match `pattern` or `pattern` contains\n",
        "      unsupported wildcards.\n",
        "  \"\"\"\n",
        "  assert len(os.path.sep) == 1\n",
        "  if \"?\" in pattern:\n",
        "    raise ValueError(\"'?' in the pattern is not supported.\")\n",
        "  if \"[\" in pattern:\n",
        "    raise ValueError(\"'[' in the pattern is not supported.\")\n",
        "  pattern_parts = (re.escape(part) for part in pattern.split(\"*\"))\n",
        "  pattern_re = re.compile(f\"([^{re.escape(os.path.sep)}]*)\".join(pattern_parts))\n",
        "  m = pattern_re.match(filename)\n",
        "  if m is None:\n",
        "    raise ValueError(f\"{filename!r} does not match the pattern {pattern!r}.\")\n",
        "  return tuple(m.groups())\n",
        "\n",
        "\n",
        "def test_get_glob_substitutions():\n",
        "  assert get_glob_substitutions(\"foo\", \"foo\") == ()\n",
        "  assert get_glob_substitutions(\"*-foo\", \"bar-foo\") == (\"bar\",)\n",
        "  assert get_glob_substitutions(\"*-bar-*\", \"foo-bar-baz\") == (\"foo\", \"baz\")\n",
        "\n",
        "\n",
        "def duration_for_spreadsheet(value) -> str:\n",
        "  total_seconds = int(value.total_seconds())\n",
        "  hours = total_seconds // 3600\n",
        "  remaining_seconds = total_seconds % 3600\n",
        "  return f\"{hours}:{remaining_seconds // 60:02d}:{remaining_seconds % 60:02d}\"\n",
        "\n",
        "\n",
        "def duration_string_for_spreadsheet(duration: cfr_json.DurationString) -> str:\n",
        "  return duration_for_spreadsheet(cfr_json.parse_duration_string(duration))\n",
        "\n",
        "\n",
        "test_get_glob_substitutions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UyAZd59TLc2"
      },
      "source": [
        "## Upload scenarios and solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6mXfeDxgA4M"
      },
      "source": [
        "### Upload via browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VJe2O3HTSTq"
      },
      "source": [
        "By running the cell below, you can upload scenarios and solutions either by\n",
        "uploading two JSON files, or by uploading one or more ZIP files.\n",
        "\n",
        "When uploading JSON files, there must be exactly two of them, one for the\n",
        "scenario and one for the solution. The file that has \"solution\" or \"response\" in\n",
        "its name will be used as the solution file, and the file that has \"scenario\" or\n",
        "\"request\" in its name will be used as the corresponding scenario file. The newly\n",
        "added scenario has name `name` (which needs to be filled before uploading the\n",
        "files). When the uploader fails to identify a scenario and a solution, the\n",
        "upload fails.\n",
        "\n",
        "When uploading a ZIP file, the ZIP file must be a scenario-solution zip file\n",
        "compatible with the fleet routing app, i.e. it must contain two files called\n",
        "\"scenario.json\" and \"solution.json\". When it also contains a file called\n",
        "\"parking.json\", it is treated as a parking location data file as used in\n",
        "[`two_step_routing_main.py`](https://github.com/google/cfr/blob/main/examples/two_step_routing/two_step_routing_main.py).\n",
        "The newly added scenario has the name \"{name}/{zip filename}\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zqhY5PX-TZvD"
      },
      "outputs": [],
      "source": [
        "def upload_local_scenario_and_solution():\n",
        "  name = \"\"  # @param {type: \"string\"}\n",
        "  uploaded_files = files.upload()\n",
        "  print()\n",
        "\n",
        "  # If there are exactly two files, try to interpret them as a scenario/solution\n",
        "  # pair. This works only if they are both JSON files and have the right names.\n",
        "  if len(uploaded_files) == 2:\n",
        "    scenario_file = None\n",
        "    scenario_bytes = None\n",
        "    solution_file = None\n",
        "    solution_bytes = None\n",
        "    parking_file = None\n",
        "    parking_bytes = None\n",
        "    # Look for a scenario and a solution.\n",
        "    for filename, contents in uploaded_files.items():\n",
        "      if not filename.endswith(\".json\"):\n",
        "        continue\n",
        "      if \"solution\" in filename or \"response\" in filename:\n",
        "        solution_file = filename\n",
        "        solution_bytes = contents\n",
        "      elif \"scenario\" in filename or \"request\" in filename:\n",
        "        scenario_file = filename\n",
        "        scenario_bytes = contents\n",
        "      elif \"parking\" in filename:\n",
        "        parking_file = filename\n",
        "        parking_bytes = contents\n",
        "      else:\n",
        "        print(\"{filename} looks neither like a scenario nor a solution.\")\n",
        "    if scenario_file is not None and solution_file is not None:\n",
        "      scenario = add_scenario_and_solution_from_bytes(\n",
        "          name,\n",
        "          scenario_bytes=scenario_bytes,\n",
        "          solution_bytes=solution_bytes,\n",
        "          parking_bytes=parking_bytes,\n",
        "      )\n",
        "      print(\n",
        "          f\"Added scenario: {scenario.name!r} from {scenario_file} and\"\n",
        "          f\" {solution_file}\"\n",
        "      )\n",
        "      if parking_file is not None:\n",
        "        print(f\"Loaded parking data from {parking_file}.\")\n",
        "      return\n",
        "\n",
        "  # Otherwise, go through all ZIP files and try to treat them as the fleet\n",
        "  # routing app ZIP files.\n",
        "  for filename, contents in uploaded_files.items():\n",
        "    if not filename.endswith(\".zip\"):\n",
        "      continue\n",
        "    with zipfile.ZipFile(io.BytesIO(contents), mode=\"r\") as zipped_file:\n",
        "      files_in_zip = set(zipped_file.namelist())\n",
        "      if (\n",
        "          \"solution.json\" not in files_in_zip\n",
        "          or \"scenario.json\" not in files_in_zip\n",
        "      ):\n",
        "        continue\n",
        "\n",
        "      scenario_bytes = zipped_file.read(\"scenario.json\")\n",
        "      solution_bytes = zipped_file.read(\"solution.json\")\n",
        "      parking_bytes = None\n",
        "      try:\n",
        "        parking_bytes = zipped_file.read(\"parking.json\")\n",
        "      except KeyError:\n",
        "        pass\n",
        "      scenario_name = f\"{name}/{filename}\" if name else filename\n",
        "      add_scenario_and_solution_from_bytes(\n",
        "          scenario_name,\n",
        "          scenario_bytes=scenario_bytes,\n",
        "          solution_bytes=solution_bytes,\n",
        "          parking_bytes=parking_bytes,\n",
        "      )\n",
        "      print(f\"Added scenario {scenario_name!r} from zip {filename}\")\n",
        "\n",
        "\n",
        "upload_local_scenario_and_solution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7PVQWUsf3iF"
      },
      "source": [
        "### Load multiple scenarios from a filesystem (advanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99HkWZqbT5t"
      },
      "source": [
        "Multiple scenarios from the local filesystem of the runtime can be added in a\n",
        "single step by using filenames with wildcards to find scenario, solution, and\n",
        "optionally also parking data files. At this moment, only `*` is supported.\n",
        "\n",
        "The loader first finds all solution JSON files by looking up all files matching\n",
        "`solution_pattern`. Then, it uses the wildcard substitutions from the solution\n",
        "pattern together with `name_template`, `scenario_template`, and\n",
        "`parking_template` to create the name of the scenario/solution pair used in the\n",
        "reports, and to find the scenario file and the parking location data file.\n",
        "\n",
        "The templates can have two formats:\n",
        "\n",
        "*   If the template contains the `*` character(s), then it must contain the same\n",
        "    number of `*` characters as `solution_pattern`, and each `*` is replaced\n",
        "    with the same substitution string as the corresponding `*` in\n",
        "    `solution_pattern`.\n",
        "*   If the template does not contain the `*` character, then the file name is\n",
        "    created using `template.format(*substitutions)` where `substitutions` is a\n",
        "    tuple of all substitutions in for `solution_pattern`.\n",
        "\n",
        "When `parking_template` is empty, the loader assumes that the scenarios and\n",
        "solutions do not have parking data and loads only the scenario and solution\n",
        "files. When the scenario file or parking file (when `parking_template` is not\n",
        "empty) for a given solution does not exist, then this solution is ignored.\n",
        "\n",
        "Examples:\n",
        "\n",
        "*   When `solution_pattern` is `*-*-solution.json`, `scenario_template` is\n",
        "    `*-*-scenario.json`, and there is a file `20231003-paris-solution.json`, the\n",
        "    loader will look for `20231003-paris-scenario.json` as the scenario file.\n",
        "*   When `solution_pattern` is `*-*-solution-*.json`, `scenario_template` is\n",
        "    `{0}-{1}-scenario.json`, and `parking_template` is `{0}-{1}-parking.json`,\n",
        "    and there is a file `20231003-paris-solution-1800s.json`, the loader will\n",
        "    look for `20231003-paris-scenario.json` and `20231003-paris-parking.json` as\n",
        "    the scenario and parking files.\n",
        "\n",
        "When `dry_run` is ticked, the files are matched, paired, and scenario names are\n",
        "printed, but the scenarios are not loaded. Use this to test the pattern and\n",
        "`name_template`. When `clean_existing` is ticked, all scenarios that were loaded\n",
        "previously will be removed before loading the new ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xmbl1D5fitTU"
      },
      "outputs": [],
      "source": [
        "def _match_files_and_group_by_substitutions(\n",
        "    pattern: str,\n",
        ") -> Mapping[tuple[str, ...], str]:\n",
        "  \"\"\"Finds files matching `pattern` and groups them by wildcard substitutions.\"\"\"\n",
        "  files = glob.glob(pattern)\n",
        "  matching_files = {}\n",
        "  for filename in files:\n",
        "    substitutions = get_glob_substitutions(pattern, filename)\n",
        "    # The following assert should never fail if the matching algorithm is\n",
        "    # deterministic.\n",
        "    assert (\n",
        "        substitutions not in matching_files\n",
        "    ), \"Multiple files with the same substitutions.\"\n",
        "    matching_files[substitutions] = filename\n",
        "  return matching_files\n",
        "\n",
        "\n",
        "def _apply_substitutions(pattern, substitutions):\n",
        "  num_wildcards = pattern.count(\"*\")\n",
        "  if num_wildcards > 0:\n",
        "    if num_wildcards != len(substitutions):\n",
        "      raise ValueError(\n",
        "          \"The number of substitutions in the pattern does not match the number\"\n",
        "          \" of provided values.\"\n",
        "      )\n",
        "    filename = pattern\n",
        "    for substitution in substitutions:\n",
        "      filename = filename.replace(\"*\", substitution, 1)\n",
        "    return filename\n",
        "  else:\n",
        "    return pattern.format(*substitutions)\n",
        "\n",
        "\n",
        "def add_multiple_scenarios_and_solutions():\n",
        "  dry_run = False  # @param{type: \"boolean\"}\n",
        "  clear_existing = False  # @param{type: \"boolean\"}\n",
        "  name_template = \"\"  # @param{type: \"string\"}\n",
        "  solution_pattern = \"\"  # @param{type: \"string\"}\n",
        "  scenario_template = \"\"  # @param{type: \"string\"}\n",
        "  parking_template = \"\"  # @param{type: \"string\"}\n",
        "\n",
        "  solution_matches = _match_files_and_group_by_substitutions(solution_pattern)\n",
        "\n",
        "  if not dry_run and clear_existing:\n",
        "    _scenarios.clear()\n",
        "\n",
        "  progressbar = ipywidgets.IntProgress(\n",
        "      value=0,\n",
        "      min=0,\n",
        "      max=len(solution_matches),\n",
        "      description=\"Loading:\",\n",
        "  )\n",
        "  display.display(progressbar)\n",
        "\n",
        "  new_scenarios = []\n",
        "  overwritten_scenarios = []\n",
        "\n",
        "  scenario_not_found = []\n",
        "  parking_not_found = []\n",
        "\n",
        "  for substitutions, solution_file in solution_matches.items():\n",
        "    if not utils.is_non_empty_file(solution_file):\n",
        "      continue\n",
        "    name = _apply_substitutions(name_template, substitutions)\n",
        "    scenario_file = _apply_substitutions(scenario_template, substitutions)\n",
        "    if not utils.is_non_empty_file(scenario_file):\n",
        "      scenario_not_found.append(name)\n",
        "      continue\n",
        "    parking_file = None\n",
        "    if parking_template:\n",
        "      parking_file = _apply_substitutions(parking_template, substitutions)\n",
        "      if not utils.is_non_empty_file(parking_file):\n",
        "        parking_not_found.append(name)\n",
        "        continue\n",
        "\n",
        "    if not clear_existing and name in _scenarios:\n",
        "      overwritten_scenarios.append(name)\n",
        "    else:\n",
        "      new_scenarios.append(name)\n",
        "\n",
        "    if not dry_run:\n",
        "      add_scenario_and_solution_from_file(\n",
        "          name, scenario_file, solution_file, parking_file\n",
        "      )\n",
        "    progressbar.value += 1\n",
        "\n",
        "  message = []\n",
        "  if scenario_not_found:\n",
        "    message.append(\n",
        "        \"**Scenario file was not found for**: \"\n",
        "        + \", \".join(sorted(scenario_not_found))\n",
        "    )\n",
        "  if parking_not_found:\n",
        "    message.append(\n",
        "        \"**Parking file was not found for**: \"\n",
        "        + \", \".join(sorted(parking_not_found))\n",
        "    )\n",
        "\n",
        "  if new_scenarios:\n",
        "    message.append(\n",
        "        f\"**Added {len(new_scenarios)} new scenario(s)**: \"\n",
        "        + \", \".join(sorted(new_scenarios))\n",
        "    )\n",
        "  if overwritten_scenarios:\n",
        "    message.append(\n",
        "        f\"**Overwrote {len(overwritten_scenarios)} existing scenario(s)**: \"\n",
        "        + \", \".join(sorted(overwritten_scenarios))\n",
        "    )\n",
        "  if not new_scenarios and not overwritten_scenarios:\n",
        "    message.append(\"No scenarios were added. Check that the paths are correct.\")\n",
        "\n",
        "  display.clear_output()\n",
        "  display.display(display.Markdown(\"\\n\\n\".join(message)))\n",
        "\n",
        "\n",
        "add_multiple_scenarios_and_solutions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsrZT8JtVUi6"
      },
      "source": [
        "## Basic request/response data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d-rGxu5ewgXl"
      },
      "outputs": [],
      "source": [
        "# @title Solution metrics\n",
        "\n",
        "\n",
        "def get_metrics(scenario):\n",
        "  # TODO(ondrasej): If metrics are not available, recompute them from route\n",
        "  # details instead of taking an empty struct that will be presented as\n",
        "  # all-zeros.\n",
        "  metrics = scenario.solution.get(\"metrics\", {})\n",
        "  aggregated_metrics = metrics.get(\"aggregatedRouteMetrics\", {})\n",
        "\n",
        "  data = {\n",
        "      \"total cost\": round(metrics.get(\"totalCost\", 0), 2),\n",
        "      \"total duration\": duration_string_for_spreadsheet(\n",
        "          aggregated_metrics.get(\"totalDuration\", \"0s\")\n",
        "      ),\n",
        "      \"wait duration\": duration_string_for_spreadsheet(\n",
        "          aggregated_metrics.get(\"waitDuration\", \"0s\")\n",
        "      ),\n",
        "      \"delay duration\": duration_string_for_spreadsheet(\n",
        "          aggregated_metrics.get(\"delayDuration\", \"0s\")\n",
        "      ),\n",
        "      \"travel duration\": duration_string_for_spreadsheet(\n",
        "          aggregated_metrics.get(\"travelDuration\", \"0s\")\n",
        "      ),\n",
        "      \"travel distance meters\": aggregated_metrics.get(\n",
        "          \"travelDistanceMeters\", 0\n",
        "      ),\n",
        "      \"skipped mandatory shipments\": metrics.get(\n",
        "          \"skippedMandatoryShipmentCount\", 0\n",
        "      ),\n",
        "      \"used vehicles\": metrics.get(\"usedVehicleCount\", 0),\n",
        "  }\n",
        "  for cost_name, cost_value in metrics.get(\"costs\", {}).items():\n",
        "    readable_name = cost_name.split(\".\")[-1]\n",
        "    data[readable_name] = round(cost_value, 2)\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rY6zM0_FQsGB"
      },
      "outputs": [],
      "source": [
        "# @title Aggregated shipment statistics\n",
        "\n",
        "\n",
        "def _has_time_window(shipment):\n",
        "  for delivery in shipment.get(\"deliveries\", ()):\n",
        "    if \"timeWindows\" in delivery:\n",
        "      return True\n",
        "  for delivery in shipment.get(\"pickups\", ()):\n",
        "    if \"timeWindows\" in delivery:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def get_basic_shipment_stats(scenario):\n",
        "  include_arrival_and_departure_virtual_shipments = False  # @param {type: \"boolean\"}\n",
        "  high_priority_shipment_threshold = None  # @param\n",
        "\n",
        "  shipments = scenario.shipments\n",
        "  filtered_shipment_index_map = {}\n",
        "  if not include_arrival_and_departure_virtual_shipments:\n",
        "    filtered_shipments = []\n",
        "    for shipment_index, shipment in enumerate(shipments):\n",
        "      label = shipment.get(\"label\", \"\")\n",
        "      if label.endswith(\" arrival\") or label.endswith(\" departure\"):\n",
        "        continue\n",
        "      filtered_shipment_index_map[shipment_index] = len(filtered_shipments)\n",
        "      filtered_shipments.append(shipment)\n",
        "    shipments = filtered_shipments\n",
        "  else:\n",
        "    filtered_shipment_index_map = {i: i for i in range(len(shipments))}\n",
        "\n",
        "  # Filtering shipments may have changed shipment indices. Whenever we work with\n",
        "  # a shipment index from the unfiltered (raw) request/response, we need to run\n",
        "  # them through filtered_shipment_index_map.\n",
        "  def filtered_indices(indices: Iterable[int]) -> Set[int]:\n",
        "    filtered_indices = set()\n",
        "    for index in indices:\n",
        "      filtered_index = filtered_shipment_index_map.get(index)\n",
        "      if filtered_index is not None:\n",
        "        filtered_indices.add(filtered_index)\n",
        "    return filtered_indices\n",
        "\n",
        "  skipped_shipments = scenario.skipped_shipments\n",
        "  skipped_shipment_indices = filtered_indices(\n",
        "      skipped_shipment.get(\"index\", 0) for skipped_shipment in skipped_shipments\n",
        "  )\n",
        "\n",
        "  num_cfr_shipments_from_parking = 0\n",
        "  num_actual_shipments_from_parking = 0\n",
        "\n",
        "  if scenario.parking_for_shipment is not None:\n",
        "    num_cfr_shipments_from_parking = len(scenario.parking_for_shipment)\n",
        "    for raw_shipment_index in scenario.parking_for_shipment:\n",
        "      shipment_index = filtered_shipment_index_map.get(raw_shipment_index)\n",
        "      if shipment_index is None:\n",
        "        continue\n",
        "      shipment = shipments[shipment_index]\n",
        "      num_actual_shipments_from_parking += (\n",
        "          shipment.get(\"label\", \"\").count(\",\") + 1\n",
        "      )\n",
        "\n",
        "  shipments_with_time_window = [\n",
        "      shipment for shipment in shipments if _has_time_window(shipment)\n",
        "  ]\n",
        "  skipped_shipments_with_time_window = [\n",
        "      shipment\n",
        "      for shipment_index, shipment in enumerate(shipments)\n",
        "      if _has_time_window(shipment)\n",
        "      and shipment_index in skipped_shipment_indices\n",
        "  ]\n",
        "  if high_priority_shipment_threshold is not None:\n",
        "    high_priority_shipments = [\n",
        "        shipment\n",
        "        for shipment in shipments\n",
        "        if shipment.get(\"penaltyCost\", 0) >= high_priority_shipment_threshold\n",
        "    ]\n",
        "    skipped_high_priority = [\n",
        "        shipment\n",
        "        for shipment_index, shipment in enumerate(shipments)\n",
        "        if shipment_index in skipped_shipment_indices\n",
        "        and shipment.get(\"penaltyCost\", 0) >= high_priority_shipment_threshold\n",
        "    ]\n",
        "  shipment_stats = {\n",
        "      \"# CFR shipments\": len(shipments),\n",
        "      \"# actual shipments\": sum(\n",
        "          shipment[\"label\"].count(\",\") + 1 for shipment in shipments\n",
        "      ),\n",
        "  }\n",
        "  if high_priority_shipment_threshold is not None:\n",
        "    shipment_stats[\"# high priority CFR shipments\"] = len(\n",
        "        high_priority_shipments\n",
        "    )\n",
        "    shipment_stats[\"# high priority actual shipments\"] = sum(\n",
        "        shipment[\"label\"].count(\",\") + 1 for shipment in high_priority_shipments\n",
        "    )\n",
        "\n",
        "  shipment_stats[\"# CFR shipments w/TW\"] = len(shipments_with_time_window)\n",
        "  shipment_stats[\"# actual shipments w/TW\"] = sum(\n",
        "      shipment[\"label\"].count(\",\") + 1\n",
        "      for shipment in shipments_with_time_window\n",
        "  )\n",
        "  shipment_stats[\"# skipped CFR shipments\"] = len(skipped_shipments)\n",
        "  shipment_stats[\"# skipped actual shipments\"] = sum(\n",
        "      shipment[\"label\"].count(\",\") + 1 for shipment in skipped_shipments\n",
        "  )\n",
        "  if high_priority_shipment_threshold is not None:\n",
        "    shipment_stats[\"# skipped high priority CFR shipments\"] = len(\n",
        "        skipped_high_priority\n",
        "    )\n",
        "    shipment_stats[\"# skipped high priority actual shipments\"] = sum(\n",
        "        shipment[\"label\"].count(\",\") + 1 for shipment in skipped_high_priority\n",
        "    )\n",
        "\n",
        "  shipment_stats[\"# skipped CFR shipments w/TW\"] = len(\n",
        "      skipped_shipments_with_time_window\n",
        "  )\n",
        "  shipment_stats[\"# skipped actual shipments w/TW\"] = sum(\n",
        "      shipment[\"label\"].count(\",\") + 1\n",
        "      for shipment in skipped_shipments_with_time_window\n",
        "  )\n",
        "  shipment_stats[\"# CFR shipments from parking\"] = (\n",
        "      num_cfr_shipments_from_parking\n",
        "  )\n",
        "  shipment_stats[\"# actual shipments from parking\"] = (\n",
        "      num_actual_shipments_from_parking\n",
        "  )\n",
        "  shipment_stats[\"penalty cost\"] = sum(\n",
        "      shipments[shipment_index].get(\"penaltyCost\", 0)\n",
        "      for shipment_index in skipped_shipment_indices\n",
        "  )\n",
        "\n",
        "  return shipment_stats\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_basic_shipment_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZwW5I1kQ2M0H"
      },
      "outputs": [],
      "source": [
        "# @title Aggregated vehicle statistics\n",
        "\n",
        "\n",
        "def _safe_percentage(value, maximum) -> str:\n",
        "  if not maximum:\n",
        "    # The maximum is zero or a zero-like value (e.g. datetime.timedelta of zero\n",
        "    # duration).\n",
        "    return \"\"\n",
        "  return f\"{100 * value / maximum:.2f} %\"\n",
        "\n",
        "\n",
        "def get_basic_vehicle_stats(scenario):\n",
        "  uturn_threshold_degrees = 170  # @param{type: \"number\"}\n",
        "\n",
        "  warp_threshold_meters = 0  # @param{type: \"number\"}\n",
        "\n",
        "  vehicles = scenario.vehicles\n",
        "  routes = scenario.routes\n",
        "\n",
        "  max_working_hours = datetime.timedelta()\n",
        "  soft_working_hours = datetime.timedelta()\n",
        "  actual_working_hours = datetime.timedelta()\n",
        "  wait_hours = datetime.timedelta()\n",
        "  negative_wait_hours = datetime.timedelta()\n",
        "  travel_hours = datetime.timedelta()\n",
        "  travel_distance_meters = 0\n",
        "\n",
        "  num_uturns = 0\n",
        "\n",
        "  num_warp_points = 0\n",
        "  warp_distance_meters = 0\n",
        "\n",
        "  num_time_travel = 0\n",
        "  num_hard_time_travel = 0\n",
        "  for vehicle, route in zip(vehicles, routes, strict=True):\n",
        "    route_metrics = route.get(\"metrics\", {})\n",
        "\n",
        "    max_working_hours += cfr_json.get_vehicle_max_working_hours(\n",
        "        scenario.model, vehicle\n",
        "    )\n",
        "    soft_working_hours += cfr_json.get_vehicle_max_working_hours(\n",
        "        scenario.model, vehicle, soft_limit=True\n",
        "    )\n",
        "    actual_working_hours += cfr_json.get_vehicle_actual_working_hours(route)\n",
        "    num_time_travel += cfr_json.get_num_decreasing_visit_times(\n",
        "        scenario.model, route, consider_visit_duration=True\n",
        "    )\n",
        "    num_hard_time_travel += cfr_json.get_num_decreasing_visit_times(\n",
        "        scenario.model, route, consider_visit_duration=False\n",
        "    )\n",
        "    wait_hours += max(\n",
        "        datetime.timedelta(), analysis.get_vehicle_wait_hours(route)\n",
        "    )\n",
        "    negative_wait_hours += analysis.get_vehicle_negative_wait_hours(route)\n",
        "    travel_hours += analysis.get_vehicle_travel_hours(route)\n",
        "    travel_distance_meters += route_metrics.get(\"travelDistanceMeters\", 0)\n",
        "\n",
        "    uturns = analysis.get_visit_turn_angles(\n",
        "        scenario.model, route, threshold_angle_degrees=uturn_threshold_degrees\n",
        "    )\n",
        "    num_uturns += sum(1 for _ in uturns)\n",
        "\n",
        "    for warp_point in analysis.get_visit_warp_distances(\n",
        "        scenario.model, route, threshold_meters=warp_threshold_meters\n",
        "    ):\n",
        "      num_warp_points += 1\n",
        "      warp_distance_meters += warp_point.warp_distance_meters\n",
        "\n",
        "  return {\n",
        "      \"# vehicles\": len(vehicles),\n",
        "      \"max working time\": duration_for_spreadsheet(max_working_hours),\n",
        "      \"soft working time\": duration_for_spreadsheet(soft_working_hours),\n",
        "      \"actual working time\": duration_for_spreadsheet(actual_working_hours),\n",
        "      \"wait time\": duration_for_spreadsheet(wait_hours),\n",
        "      \"travel time\": duration_for_spreadsheet(travel_hours),\n",
        "      \"travel distance meters\": travel_distance_meters,\n",
        "      \"max working time %\": _safe_percentage(\n",
        "          actual_working_hours, max_working_hours\n",
        "      ),\n",
        "      \"soft working time %\": _safe_percentage(\n",
        "          actual_working_hours, soft_working_hours\n",
        "      ),\n",
        "      \"wait time %\": _safe_percentage(wait_hours, actual_working_hours),\n",
        "      \"# soft time travel\": str(num_time_travel),\n",
        "      \"negative wait time\": duration_for_spreadsheet(negative_wait_hours),\n",
        "      \"# time travel\": str(num_hard_time_travel),\n",
        "      \"# uturns\": num_uturns,\n",
        "      \"# warp points\": num_warp_points,\n",
        "      \"# warp distance meters\": warp_distance_meters,\n",
        "  }\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_basic_vehicle_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WXugr2F3c4Bc"
      },
      "outputs": [],
      "source": [
        "# @title Shipment list\n",
        "\n",
        "\n",
        "def get_shipment_list(scenario):\n",
        "  shipments = scenario.shipments\n",
        "\n",
        "  shipment_visits = collections.defaultdict(list)\n",
        "  shipment_to_vehicle = {}\n",
        "  for route_index, route in enumerate(scenario.routes):\n",
        "    for visit_index, visit in enumerate(route.get(\"visits\", ())):\n",
        "      shipment_index = visit.get(\"shipmentIndex\", 0)\n",
        "      shipment_to_vehicle[shipment_index] = route_index\n",
        "      shipment_visits[shipment_index].append(visit)\n",
        "\n",
        "  data = []\n",
        "  for shipment_index, shipment in enumerate(shipments):\n",
        "    pickup_time_windows = []\n",
        "    pickup_durations = []\n",
        "    pickups = shipment.get(\"pickups\", ())\n",
        "    for pickup in pickups:\n",
        "      if (time_windows := pickup.get(\"timeWindows\")) is not None:\n",
        "        pickup_time_windows.append(human_readable.time_windows(time_windows))\n",
        "      pickup_durations.append(pickup.get(\"duration\", \"0s\"))\n",
        "    delivery_time_windows = []\n",
        "    delivery_durations = []\n",
        "    deliveries = shipment.get(\"deliveries\", ())\n",
        "    for delivery in deliveries:\n",
        "      if (time_windows := delivery.get(\"timeWindows\")) is not None:\n",
        "        delivery_time_windows.append(human_readable.time_windows(time_windows))\n",
        "      delivery_durations.append(delivery.get(\"duration\", \"0s\"))\n",
        "    vehicle_index = shipment_to_vehicle.get(shipment_index)\n",
        "    vehicle_label = (\n",
        "        f\"{vehicle_index}: {scenario.vehicle_label(vehicle_index)}\"\n",
        "        if vehicle_index is not None\n",
        "        else \"\"\n",
        "    )\n",
        "    # Each shipment has at most two visits: a pickup and a delivery.\n",
        "    pickup_time = \"\"\n",
        "    delivery_time = \"\"\n",
        "    for visit in shipment_visits[shipment_index]:\n",
        "      if visit.get(\"isPickup\"):\n",
        "        pickup_time = visit[\"startTime\"]\n",
        "      else:\n",
        "        delivery_time = visit[\"startTime\"]\n",
        "    data.append({\n",
        "        \"shipment_index\": shipment_index,\n",
        "        \"label\": shipment.get(\"label\", \"\"),\n",
        "        \"vehicle\": vehicle_label,\n",
        "        \"pickup time\": pickup_time,\n",
        "        \"delivery time\": delivery_time,\n",
        "        \"type\": shipment.get(\"shipmentType\", \"\"),\n",
        "        \"penalty\": shipment.get(\"penaltyCost\", -1),\n",
        "        \"pickup time windows\": \" | \".join(pickup_time_windows),\n",
        "        \"pickup durations\": \" | \".join(pickup_durations),\n",
        "        \"delivery time windows\": \" | \".join(delivery_time_windows),\n",
        "        \"delivery durations\": \" | \".join(delivery_durations),\n",
        "        \"allowed vehicles\": \", \".join(\n",
        "            scenario.vehicle_labels(shipment.get(\"allowedVehicleIndices\", ()))\n",
        "        ),\n",
        "        \"parking tag\": scenario.parking_for_shipment.get(shipment_index, \"\"),\n",
        "    })\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_shipment_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "guyLsHrj6Hi3"
      },
      "outputs": [],
      "source": [
        "# @title Vehicle list\n",
        "\n",
        "\n",
        "def get_vehicle_list(scenario):\n",
        "  used_vehicles_only = False  # @param{type: \"boolean\"}\n",
        "  split_by_breaks = True  # @param{type: \"boolean\"}\n",
        "  uturn_threshod_degrees = 170  # @param{type: \"number\"}\n",
        "  warp_threshold_meters = 50  # @param{type: \"number\"}\n",
        "  show_duration_statistics = False  # @param{type: \"boolean\"}\n",
        "  show_traffic_statistics = False  # @param{type: \"boolean\"}\n",
        "  show_parking_statistics = False  # @param{type: \"boolean\"}\n",
        "  parking_data = scenario.parking_location_data\n",
        "  shipments = scenario.shipments\n",
        "  data = []\n",
        "\n",
        "  for vehicle_index, route in enumerate(scenario.routes):\n",
        "    vehicle = scenario.vehicles[vehicle_index]\n",
        "    route_metrics = route.get(\"metrics\", {})\n",
        "    row = {\n",
        "        \"vehicle_index\": vehicle_index,\n",
        "        \"label\": scenario.vehicle_label(vehicle_index),\n",
        "        \"# shipments\": \"\",\n",
        "        \"travel distance meters\": route_metrics.get(\"travelDistanceMeters\", 0),\n",
        "        \"# u-turns\": \"\",\n",
        "        \"# warp points\": \"\",\n",
        "        \"warp distance (m)\": \"\",\n",
        "    }\n",
        "    if show_duration_statistics:\n",
        "      row[\"duration\"] = \"\"\n",
        "      row[\"first to last visit\"] = \"\"\n",
        "      row[\"start time\"] = \"\"\n",
        "      row[\"first visit\"] = \"\"\n",
        "      row[\"90% shipments delivered\"] = \"\"\n",
        "      row[\"last visit\"] = \"\"\n",
        "      row[\"end time\"] = \"\"\n",
        "      row[\"max working time\"] = \"\"\n",
        "      row[\"soft working time\"] = \"\"\n",
        "      row[\"actual working time\"] = \"\"\n",
        "      row[\"wait time\"] = \"\"\n",
        "    if show_traffic_statistics:\n",
        "      row[\"negative wait time\"] = \"\"\n",
        "      row[\"# time travel\"] = \"\"\n",
        "      row[\"# soft time travel\"] = \"\"\n",
        "    if show_parking_statistics:\n",
        "      row[\"# ping-pongs\"] = \"\"\n",
        "      row[\"# bad ping-pongs\"] = \"\"\n",
        "      row[\"bad ping-pong tags\"] = \"\"\n",
        "      row[\"# sandwiches\"] = \"\"\n",
        "      row[\"# bad sandwiches\"] = \"\"\n",
        "      row[\"bad sandwich tags\"] = \"\"\n",
        "      row[\"# sandwiches (v1)\"] = \"\"\n",
        "      row[\"# bad sandwiches (v1)\"] = \"\"\n",
        "      row[\"bad sandwich tags (v1)\"] = \"\"\n",
        "\n",
        "    if show_duration_statistics:\n",
        "      _set_if_enabled(\n",
        "          row,\n",
        "          \"max working time\",\n",
        "          cfr_json.get_vehicle_max_working_hours(scenario.model, vehicle),\n",
        "      )\n",
        "      _set_if_enabled(\n",
        "          row,\n",
        "          \"soft working time\",\n",
        "          cfr_json.get_vehicle_max_working_hours(\n",
        "              scenario.model, vehicle, soft_limit=True\n",
        "          ),\n",
        "      )\n",
        "\n",
        "    visits = route.get(\"visits\", ())\n",
        "    if not visits:\n",
        "      # Unused vehicle. Nothing to see here.\n",
        "      if not used_vehicles_only:\n",
        "        data.append(row)\n",
        "      continue\n",
        "\n",
        "    num_ping_pongs, bad_ping_pong_tags = analysis.get_num_ping_pongs(\n",
        "        scenario, vehicle_index, split_by_breaks=split_by_breaks\n",
        "    )\n",
        "    num_sandwiches_v1, bad_sandwich_tags_v1 = analysis.get_num_sandwiches(\n",
        "        scenario, vehicle_index\n",
        "    )\n",
        "    num_sandwiches, bad_sandwich_tags = analysis.analyse_bad_sandwiches(\n",
        "        scenario, vehicle_index\n",
        "    )\n",
        "\n",
        "    num_time_travel = cfr_json.get_num_decreasing_visit_times(\n",
        "        scenario.model, route, False\n",
        "    )\n",
        "    num_soft_time_travel = cfr_json.get_num_decreasing_visit_times(\n",
        "        scenario.model, route, True\n",
        "    )\n",
        "\n",
        "    start_time = cfr_json.parse_time_string(route[\"vehicleStartTime\"])\n",
        "    end_time = cfr_json.parse_time_string(route[\"vehicleEndTime\"])\n",
        "\n",
        "    consecutive_visits = parking_data.consecutive_visits.get(vehicle_index)\n",
        "    non_consecutive_visits = parking_data.non_consecutive_visits.get(\n",
        "        vehicle_index\n",
        "    )\n",
        "\n",
        "    first_visit_start = cfr_json.parse_time_string(visits[0][\"startTime\"])\n",
        "    last_visit_start = cfr_json.parse_time_string(visits[-1][\"startTime\"])\n",
        "\n",
        "    _, shipments_90p_time = analysis.get_percentile_visit_time(\n",
        "        scenario.model, route, 90, False\n",
        "    )\n",
        "\n",
        "    num_uturns = 0\n",
        "    for _ in analysis.get_visit_turn_angles(\n",
        "        scenario.model, route, threshold_angle_degrees=uturn_threshod_degrees\n",
        "    ):\n",
        "      num_uturns += 1\n",
        "\n",
        "    num_warp_points = 0\n",
        "    total_warp_distance = 0\n",
        "    for warp_point in analysis.get_visit_warp_distances(\n",
        "        scenario.model, route, threshold_meters=warp_threshold_meters\n",
        "    ):\n",
        "      num_warp_points += 1\n",
        "      total_warp_distance += warp_point.warp_distance_meters\n",
        "\n",
        "    row[\"# shipments\"] = len(visits)\n",
        "    if show_duration_statistics:\n",
        "      row[\"duration\"] = str(end_time - start_time)\n",
        "      row[\"first to last visit\"] = str(last_visit_start - first_visit_start)\n",
        "      row[\"start time\"] = str(start_time)\n",
        "      row[\"first visit\"] = str(first_visit_start)\n",
        "      row[\"90% shipments delivered\"] = str(shipments_90p_time)\n",
        "      row[\"last visit\"] = str(last_visit_start)\n",
        "      row[\"end time\"] = str(end_time)\n",
        "      row[\"max end time\"] = cfr_json.get_vehicle_latest_end(\n",
        "          scenario.model, vehicle\n",
        "      )\n",
        "      row[\"max working time\"] = str(\n",
        "          cfr_json.get_vehicle_max_working_hours(scenario.model, vehicle)\n",
        "      )\n",
        "      row[\"soft working time\"] = str(\n",
        "          cfr_json.get_vehicle_max_working_hours(\n",
        "              scenario.model, vehicle, soft_limit=True\n",
        "          )\n",
        "      )\n",
        "      row[\"actual working time\"] = str(\n",
        "          cfr_json.get_vehicle_actual_working_hours(route)\n",
        "      )\n",
        "      row[\"wait time\"] = str(\n",
        "          max(datetime.timedelta(), analysis.get_vehicle_wait_hours(route))\n",
        "      )\n",
        "    if show_traffic_statistics:\n",
        "      row[\"negative wait time\"] = duration_for_spreadsheet(\n",
        "          analysis.get_vehicle_negative_wait_hours(route)\n",
        "      )\n",
        "      row[\"# time travel\"] = str(num_time_travel)\n",
        "      row[\"# soft time travel\"] = str(num_soft_time_travel)\n",
        "    if show_parking_statistics:\n",
        "      row[\"# ping-pongs\"] = str(num_ping_pongs)\n",
        "      row[\"# bad ping-pongs\"] = len(bad_ping_pong_tags)\n",
        "      row[\"bad ping-pong tags\"] = \", \".join(bad_ping_pong_tags)\n",
        "      row[\"# sandwiches\"] = str(num_sandwiches)\n",
        "      row[\"# bad sandwiches\"] = len(bad_sandwich_tags)\n",
        "      row[\"bad sandwich tags\"] = \", \".join(bad_sandwich_tags)\n",
        "      row[\"# sandwiches (v1)\"] = str(num_sandwiches_v1)\n",
        "      row[\"# bad sandwiches (v1)\"] = len(bad_sandwich_tags_v1)\n",
        "      row[\"bad sandwich tags (v1)\"] = \", \".join(bad_sandwich_tags_v1)\n",
        "    row[\"# u-turns\"] = num_uturns\n",
        "    row[\"# warp points\"] = num_warp_points\n",
        "    row[\"warp distance (m)\"] = total_warp_distance\n",
        "\n",
        "    data.append(row)\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_vehicle_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qon_cXhsm0GX"
      },
      "outputs": [],
      "source": [
        "# @title Skipped shipments\n",
        "\n",
        "\n",
        "def get_skipped_shipment_list(scenario):\n",
        "  data = []\n",
        "  shipments = scenario.shipments\n",
        "  for skipped_shipment in scenario.skipped_shipments:\n",
        "    skipped_shipment_index = skipped_shipment.get(\"index\", 0)\n",
        "    shipment = shipments[skipped_shipment_index]\n",
        "    allowed_vehicles = scenario.vehicle_labels(\n",
        "        shipment.get(\"allowedVehicleIndices\", ())\n",
        "    )\n",
        "    data.append({\n",
        "        \"shipment index\": skipped_shipment_index,\n",
        "        \"label\": skipped_shipment.get(\"label\", \"\"),\n",
        "        \"allowed vehicles\": allowed_vehicles,\n",
        "        \"type\": shipment.get(\"shipmentType\", \"\"),\n",
        "        \"reasons\": str(skipped_shipment.get(\"reasons\", \"\")),\n",
        "        \"penalty cost\": shipment.get(\"penaltyCost\", -1),\n",
        "    })\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_skipped_shipment_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Im3WX2b6sP-V"
      },
      "outputs": [],
      "source": [
        "# @title Shipments by time window\n",
        "\n",
        "\n",
        "def get_num_shipments_by_time_window(scenario):\n",
        "  data = []\n",
        "  shipments_by_time_window = collections.defaultdict(list)\n",
        "  skipped_shipments_by_time_window = collections.defaultdict(list)\n",
        "  # TODO(ondrasej): Make this work for pickups too.\n",
        "  for shipment_index, shipment in enumerate(scenario.shipments):\n",
        "    allowed_vehicles = \", \".join(\n",
        "        scenario.vehicle_labels(shipment.get(\"allowedVehicleIndices\", ()))\n",
        "    )\n",
        "    for delivery in shipment.get(\"deliveries\", ()):\n",
        "      time_windows = delivery.get(\"timeWindows\", ())\n",
        "      str_time_window = human_readable.time_windows(time_windows)\n",
        "      shipments_by_time_window[allowed_vehicles, str_time_window].append(\n",
        "          shipment\n",
        "      )\n",
        "      if shipment_index in scenario.skipped_shipment_indices:\n",
        "        skipped_shipments_by_time_window[\n",
        "            allowed_vehicles, str_time_window\n",
        "        ].append(shipment)\n",
        "\n",
        "  for (allowed_vehicles, time_window), shipments in sorted(\n",
        "      shipments_by_time_window.items()\n",
        "  ):\n",
        "    skipped_shipments = skipped_shipments_by_time_window.get(\n",
        "        (allowed_vehicles, time_window), ()\n",
        "    )\n",
        "    data.append({\n",
        "        \"allowed vehicles\": allowed_vehicles,\n",
        "        \"time window\": time_window or \"(none)\",\n",
        "        \"# CFR shipments\": len(shipments),\n",
        "        \"# actual shipments\": sum(\n",
        "            shipment.get(\"label\", \"\").count(\",\") + 1 for shipment in shipments\n",
        "        ),\n",
        "        \"# skipped CFR shipments\": len(skipped_shipments),\n",
        "        \"# skipped actual shipments\": sum(\n",
        "            shipment.get(\"label\", \"\").count(\",\") + 1\n",
        "            for shipment in skipped_shipments\n",
        "        ),\n",
        "    })\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_num_shipments_by_time_window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaQbPrRHaCeL"
      },
      "source": [
        "## Vehicle-shipment grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wkhvoon2aF3y"
      },
      "outputs": [],
      "source": [
        "# @title Shipments by allowed vehicles\n",
        "#\n",
        "# @markdown Groups shipments by the vehicles that can handle them as expressed\n",
        "# @markdown in the `Shipment.allowedVehicleIndices` field. Each shipment is\n",
        "# @markdown counted exactly once (appears in one row); each vehicle may appear\n",
        "# @markdown in zero, one or more rows.\n",
        "# @markdown\n",
        "# @markdown - _# shipments_ is the total number of shipments that can be handled\n",
        "# @markdown   by exactly these vehicles.\n",
        "# @markdown - _# skipped shipments_ is the number of skipped shipments in the\n",
        "# @markdown   solution that can be handled only by this group of vehicles.\n",
        "\n",
        "\n",
        "def get_vehicle_shipment_groups(scenario):\n",
        "  groups = sorted(analysis.get_vehicle_shipment_groups(scenario.model))\n",
        "  data = []\n",
        "  for vehicle_indices, shipment_indices in groups:\n",
        "    skipped_shipments_in_group = (\n",
        "        scenario.skipped_shipment_indices & shipment_indices\n",
        "    )\n",
        "    data.append({\n",
        "        \"allowed vehicles\": \", \".join(scenario.vehicle_labels(vehicle_indices)),\n",
        "        \"# shipments\": len(shipment_indices),\n",
        "        \"# skipped shipments\": len(skipped_shipments_in_group),\n",
        "    })\n",
        "\n",
        "  # Sort the list by vehicle labels to make it easier to read.\n",
        "  data.sort(key=lambda x: x[\"allowed vehicles\"])\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_vehicle_shipment_groups)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zefXzoTVx8w"
      },
      "source": [
        "## Detailed vehicle data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yk5DcFaFwKJY"
      },
      "outputs": [],
      "source": [
        "# @title Individual vehicle route\n",
        "\n",
        "\n",
        "def _get_vehicle_route_rows(scenario, vehicle_index):\n",
        "  model = scenario.scenario[\"model\"]\n",
        "\n",
        "  shipments = scenario.shipments\n",
        "  vehicles = scenario.vehicles\n",
        "\n",
        "  route = scenario.routes[vehicle_index]\n",
        "  vehicle = vehicles[vehicle_index]\n",
        "  vehicle_label = vehicle.get(\"label\", \"\")\n",
        "\n",
        "  visits = route.get(\"visits\", ())\n",
        "  if not visits:\n",
        "    output.clear(output_tags=[\"table_container\"])\n",
        "    with output.use_tags(\"table_container\", append=True):\n",
        "      print(\"The route is empty\")\n",
        "    return ()\n",
        "\n",
        "  data = []\n",
        "  transitions = route.get(\"transitions\", ())\n",
        "  start_time = cfr_json.parse_time_string(route[\"vehicleStartTime\"])\n",
        "\n",
        "  # We'll be popping elements from the list, so we need to make a copy to\n",
        "  # avoid destroying the data.\n",
        "  breaks = list(route.get(\"breaks\", ()))\n",
        "\n",
        "  # If there are no breaks, we use datetime.max as the time of the next break\n",
        "  # so that the case of no (more) breaks doesn't need any special handling\n",
        "  # in add_breaks_before_timestamp().\n",
        "  def get_next_break_start():\n",
        "    return (\n",
        "        cfr_json.parse_time_string(breaks[0][\"startTime\"])\n",
        "        if breaks\n",
        "        else _DATETIME_MAX_UTC\n",
        "    )\n",
        "\n",
        "  next_break_start = get_next_break_start()\n",
        "\n",
        "  def add_breaks_before_timestamp(timestamp):\n",
        "    nonlocal next_break_start\n",
        "    while next_break_start < timestamp:\n",
        "      current_break = breaks.pop(0)\n",
        "      data.append({\n",
        "          \"vehicle\": vehicle_label,\n",
        "          \"shipment index\": \"\",\n",
        "          \"shipment\": \"\",\n",
        "          \"shipment type\": \"\",\n",
        "          \"penalty cost\": \"\",\n",
        "          \"type\": \"break\",\n",
        "          \"latlng\": \"\",\n",
        "          \"start\": str(next_break_start),\n",
        "          \"since start\": str(next_break_start - start_time),\n",
        "          \"duration\": current_break.get(\"duration\", \"0s\"),\n",
        "          \"distance\": \"\",\n",
        "          \"transition\": \"\",\n",
        "          \"time window\": \"\",\n",
        "      })\n",
        "      next_break_start = get_next_break_start()\n",
        "\n",
        "  add_breaks_before_timestamp(start_time)\n",
        "  data.append({\n",
        "      \"vehicle\": vehicle_label,\n",
        "      \"shipment index\": \"\",\n",
        "      \"shipment\": \"start\",\n",
        "      \"shipment type\": \"\",\n",
        "      \"penalty cost\": \"\",\n",
        "      \"type\": \"\",\n",
        "      \"latlng\": human_readable.vehicle_start_location(vehicle),\n",
        "      \"start\": str(start_time),\n",
        "      \"since start\": \"0:00:00\",\n",
        "      \"duration\": \"0s\",\n",
        "      \"distance\": f\"{int(transitions[0].get('travelDistanceMeters', 0.0))} m\",\n",
        "      \"transition\": (\n",
        "          human_readable.transition_duration(transitions[0])\n",
        "          if transitions\n",
        "          else \"\"\n",
        "      ),\n",
        "      \"time window\": human_readable.time_windows(\n",
        "          vehicle.get(\"startTimeWindows\")\n",
        "      ),\n",
        "  })\n",
        "\n",
        "  turn_angles = {\n",
        "      turn.visit_index: turn.angle_degrees\n",
        "      for turn in analysis.get_visit_turn_angles(scenario.model, route, -1)\n",
        "  }\n",
        "  warp_distances = {\n",
        "      warp_point.visit_index: warp_point.warp_distance_meters\n",
        "      for warp_point in analysis.get_visit_warp_distances(\n",
        "          scenario.model, route, -1\n",
        "      )\n",
        "  }\n",
        "  for visit_index, visit in enumerate(visits):\n",
        "    visit_request = cfr_json.get_visit_request(scenario.model, visit)\n",
        "    transition_out = transitions[visit_index + 1]\n",
        "    shipment_index = visit.get(\"shipmentIndex\", 0)\n",
        "    shipment = shipments[shipment_index]\n",
        "    visit_start = cfr_json.parse_time_string(visit[\"startTime\"])\n",
        "    visit_type = \"pickup\" if visit.get(\"isPickup\") else \"delivery\"\n",
        "\n",
        "    turn_angle = turn_angles.get(visit_index)\n",
        "    turn_angle = round(turn_angle, 2) if turn_angle is not None else None\n",
        "\n",
        "    warp_distance = warp_distances.get(visit_index)\n",
        "    warp_distance = (\n",
        "        round(warp_distance, 2) if warp_distance is not None else None\n",
        "    )\n",
        "\n",
        "    add_breaks_before_timestamp(visit_start)\n",
        "    data.append({\n",
        "        \"vehicle\": vehicle_label,\n",
        "        \"shipment index\": visit.get(\"shipmentIndex\", 0),\n",
        "        \"shipment\": visit.get(\"shipmentLabel\", \"\"),\n",
        "        \"shipment type\": shipment.get(\"shipmentType\", \"\"),\n",
        "        \"penalty cost\": shipment.get(\"penaltyCost\", -1),\n",
        "        \"type\": visit_type,\n",
        "        \"latlng\": human_readable.visit_request_location(visit_request),\n",
        "        \"start\": str(visit_start),\n",
        "        \"since start\": str(visit_start - start_time),\n",
        "        \"duration\": visit_request.get(\"duration\"),\n",
        "        \"distance\": f\"{int(transition_out.get('travelDistanceMeters', 0.0))} m\",\n",
        "        \"transition\": human_readable.transition_duration(transition_out),\n",
        "        \"time window\": human_readable.time_windows(\n",
        "            visit_request.get(\"timeWindows\")\n",
        "        ),\n",
        "        \"turn angle\": turn_angle,\n",
        "        \"warp meters\": warp_distance,\n",
        "    })\n",
        "  end_time = cfr_json.parse_time_string(route[\"vehicleEndTime\"])\n",
        "\n",
        "  add_breaks_before_timestamp(end_time)\n",
        "  data.append({\n",
        "      \"vehicle\": vehicle_label,\n",
        "      \"shipment index\": \"\",\n",
        "      \"shipment\": \"end\",\n",
        "      \"type\": \"\",\n",
        "      \"latlng\": human_readable.vehicle_end_location(vehicle),\n",
        "      \"start\": str(end_time),\n",
        "      \"since start\": str(end_time - start_time),\n",
        "      \"duration\": \"0s\",\n",
        "      \"transition\": \"\",\n",
        "      \"time window\": vehicle.get(\"endTimeWindows\", \"\"),\n",
        "  })\n",
        "  add_breaks_before_timestamp(_DATETIME_MAX_UTC)\n",
        "  return data\n",
        "\n",
        "\n",
        "def create_individual_vehicle_route_ui():\n",
        "  scenario_selector = ipywidgets.Dropdown(description=\"Scenario:\", options=[])\n",
        "  vehicle_selector = ipywidgets.Dropdown(description=\"Vehicle:\", options=[])\n",
        "  refresh_button = ipywidgets.Button(description=\"Refresh\")\n",
        "\n",
        "  display.display(\n",
        "      ipywidgets.HBox(\n",
        "          children=[scenario_selector, vehicle_selector, refresh_button]\n",
        "      )\n",
        "  )\n",
        "\n",
        "  scenario = None\n",
        "\n",
        "  def on_scenario_selected(*kwargs):\n",
        "    nonlocal scenario\n",
        "    scenario = _scenarios[scenario_selector.value]\n",
        "    vehicle_selector_options = [\"(all)\"]\n",
        "    vehicle_selector_options.extend(\n",
        "        f\"{vehicle_index}: {vehicle.get('label', '')}\"\n",
        "        for vehicle_index, vehicle in enumerate(scenario.vehicles)\n",
        "    )\n",
        "    vehicle_selector.options = vehicle_selector_options\n",
        "\n",
        "  scenario_selector.observe(on_scenario_selected, names=[\"value\"])\n",
        "\n",
        "  def on_refresh(_):\n",
        "    if vehicle_selector.value == \"(all)\":\n",
        "      data = []\n",
        "      for vehicle_index in range(len(scenario.vehicles)):\n",
        "        data.extend(_get_vehicle_route_rows(scenario, vehicle_index))\n",
        "    else:\n",
        "      vehicle_index = int(vehicle_selector.value.split(\":\")[0])\n",
        "      data = _get_vehicle_route_rows(scenario, vehicle_index)\n",
        "\n",
        "    output.clear(output_tags=[\"table_container\"])\n",
        "    with output.use_tags(\"table_container\", append=True):\n",
        "      display.display(data_table.DataTable(pd.DataFrame(data)))\n",
        "\n",
        "  refresh_button.on_click(on_refresh)\n",
        "  scenario_selector.options = sorted(_scenarios.keys())\n",
        "\n",
        "\n",
        "create_individual_vehicle_route_ui()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgELzuTWV2lA"
      },
      "source": [
        "## Parking location data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI5XmIVORcgt"
      },
      "source": [
        "### Definitions\n",
        "\n",
        "*   **Parking ping-pong** is the situation where the same parking location is\n",
        "    visited by a vehicle multiple times in a row. In practice, this corresponds\n",
        "    to multiple delivery rounds from this parking and it can happen when the\n",
        "    number of shipments delivered from this parking location exceeds the\n",
        "    delivery capacity of this parking. This may also happen as an artifact of\n",
        "    the planning algorithm.\n",
        "\n",
        "    We say that a ping-pong is a **bad ping-pong** when the number of delivery\n",
        "    rounds in the ping-pong is higher than what would be required by the load\n",
        "    limits while delivering from the parking. For example, when there are 50\n",
        "    shipments delivered from parking P123 and the load limit for deliveries from\n",
        "    this parking is 20, a plan where the shipments are delivered in 4 or more\n",
        "    rounds scheduled back to back has a case of bad ping-pong. If the shipments\n",
        "    are delivered in 3 rounds scheduled back to back, this is not a case of bad\n",
        "    ping-pong.\n",
        "\n",
        "*   **Parking sandwich** is the situation where the same parking location is\n",
        "    visited multiple times by the same vehicle, but the vehicle leaves the\n",
        "    parking location between the visits. For example, when the vehicle delivers\n",
        "    shipments from parking P123, then from parking P456, and then again from\n",
        "    P123, it is a case of parking sandwich.\n",
        "\n",
        "    Parking sandwiches may appear on a route when shipments delivered from a\n",
        "    parking have time windows that are far apart, but they may also appear\n",
        "    without time windows, for example when there are no costs making the solver\n",
        "    group visits to the same parking.\n",
        "\n",
        "    We say that a sandwich is a **bad sandwich** when the separated visits to\n",
        "    the parking location are because of other reasons than time windows that are\n",
        "    far apart.\n",
        "\n",
        "*   **Parking party** is the situation where multiple vehicles visit the same\n",
        "    parking location. A parking party may happen when there are more shipments\n",
        "    delivered from the parking location than a single vehicle can handle. It may\n",
        "    also happen when the costs and constraints of a model are set up in such a\n",
        "    way that using multiple vehicles leads to a lower cost.\n",
        "\n",
        "    We say that a parking party is a **bad party** when the party happens\n",
        "    because of reasons other than vehicle/delivery capacity constraints. Note\n",
        "    that a party may also be created when there are too many shipments with the\n",
        "    same time window than a single vehicle can deliver. Such a case is also not\n",
        "    considered a bad party."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NT2lTPiMVmo8"
      },
      "outputs": [],
      "source": [
        "# @title Parking location aggregated statistics\n",
        "\n",
        "\n",
        "def get_parking_locations_summary(scenario):\n",
        "  split_by_breaks = True  # @param {type: \"boolean\"}\n",
        "  buffer_time_seconds = 3600  # @param {type: \"number\"}\n",
        "  buffer_time = datetime.timedelta(seconds=buffer_time_seconds)\n",
        "  parking_data = scenario.parking_location_data\n",
        "\n",
        "  party_stats = analysis.get_parking_party_stats(\n",
        "      scenario, buffer_time=buffer_time\n",
        "  )\n",
        "\n",
        "  num_ping_pongs = 0\n",
        "  num_bad_ping_pongs = 0\n",
        "  num_sandwiches = 0\n",
        "  num_bad_sandwiches = 0\n",
        "  num_sandwiches_v1 = 0\n",
        "  num_bad_sandwiches_v1 = 0\n",
        "  for vehicle_index in range(len(scenario.routes)):\n",
        "    num_vehicle_ping_pongs, bad_ping_pong_tags = analysis.get_num_ping_pongs(\n",
        "        scenario, vehicle_index, split_by_breaks\n",
        "    )\n",
        "    num_ping_pongs += num_vehicle_ping_pongs\n",
        "    num_bad_ping_pongs += len(bad_ping_pong_tags)\n",
        "\n",
        "    num_vehicle_sandwiches, bad_sandwich_tags = analysis.analyse_bad_sandwiches(\n",
        "        scenario, vehicle_index\n",
        "    )\n",
        "    num_sandwiches += num_vehicle_sandwiches\n",
        "    num_bad_sandwiches += len(bad_sandwich_tags)\n",
        "\n",
        "    num_vehicle_sandwiches_v1, bad_sandwich_tags_v1 = (\n",
        "        analysis.get_num_sandwiches(scenario, vehicle_index)\n",
        "    )\n",
        "    num_sandwiches_v1 += num_vehicle_sandwiches_v1\n",
        "    num_bad_sandwiches_v1 += len(bad_sandwich_tags_v1)\n",
        "\n",
        "  assert num_sandwiches == num_sandwiches_v1, (\n",
        "      \"Different versions of parking sandwich analysis return a different\"\n",
        "      \" number of all parking sandwiches.\"\n",
        "  )\n",
        "\n",
        "  return [{\n",
        "      \"# distinct parkings\": len(scenario.parking_locations),\n",
        "      \"# distinct visited parkings\": len(parking_data.all_parking_tags),\n",
        "      \"# visits to parking\": parking_data.num_all_visits_to_parking,\n",
        "      \"# parkings served by multiple vehicles\": (\n",
        "          party_stats.num_parkings_with_multiple_vehicles\n",
        "      ),\n",
        "      \"# party visits\": party_stats.num_party_visits,\n",
        "      \"# overlapping party visits\": party_stats.num_overlapping_visit_pairs,\n",
        "      \"max overlapping party visits\": (\n",
        "          party_stats.max_vehicles_at_parking_at_once\n",
        "      ),\n",
        "      \"# ping-pong visits\": sum(\n",
        "          len(visits) for visits in parking_data.consecutive_visits.values()\n",
        "      ),\n",
        "      \"# ping-pongs\": num_ping_pongs,\n",
        "      \"# bad ping-pongs\": num_bad_ping_pongs,\n",
        "      \"# sandwich visits\": sum(\n",
        "          len(visits) for visits in parking_data.non_consecutive_visits.values()\n",
        "      ),\n",
        "      \"# sandwiches\": num_sandwiches,\n",
        "      \"# bad sandwiches\": num_bad_sandwiches,\n",
        "      \"# bad sandwiches (v1)\": num_bad_sandwiches_v1,\n",
        "  }]\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_parking_locations_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WyRohVXFaCEK"
      },
      "outputs": [],
      "source": [
        "# @title Parking location list\n",
        "\n",
        "\n",
        "def _merge_overlaps(overlaps):\n",
        "  \"\"\"Merges back-to-back overlaps by the same vehicle.\n",
        "\n",
        "  Parking ping-pongs may create multiple overlaps that are back-to-back and that\n",
        "  use the same vehicles. This is hard to read for the user and does not change\n",
        "  the fact that there are multiple vehicles in the parking, so we just merge\n",
        "  those into a single overlap.\n",
        "  \"\"\"\n",
        "  previous_vehicles = ()\n",
        "  previous_tag = None\n",
        "  previous_end_time = None\n",
        "  start_time = None\n",
        "  for overlap in overlaps:\n",
        "    if start_time is None:\n",
        "      start_time = overlap.start_time\n",
        "    elif (\n",
        "        previous_vehicles != overlap.vehicles\n",
        "        or previous_tag != overlap.parking_tag\n",
        "        or previous_end_time != overlap.start_time\n",
        "    ):\n",
        "      yield analysis.OverlappingParkingVisit(\n",
        "          parking_tag=previous_tag,\n",
        "          start_time=start_time,\n",
        "          vehicles=previous_vehicles,\n",
        "          end_time=previous_end_time,\n",
        "      )\n",
        "      start_time = overlap.start_time\n",
        "    previous_vehicles = overlap.vehicles\n",
        "    previous_tag = overlap.parking_tag\n",
        "    previous_end_time = overlap.end_time\n",
        "\n",
        "  if start_time is not None:\n",
        "    yield analysis.OverlappingParkingVisit(\n",
        "        parking_tag=previous_tag,\n",
        "        start_time=start_time,\n",
        "        end_time=previous_end_time,\n",
        "        vehicles=previous_vehicles,\n",
        "    )\n",
        "\n",
        "\n",
        "def get_parking_location_list(scenario):\n",
        "  parking_data = scenario.parking_location_data\n",
        "  party_stats = analysis.get_parking_party_stats(\n",
        "      scenario, datetime.timedelta(0)\n",
        "  )\n",
        "  vehicles = scenario.vehicles\n",
        "  data = []\n",
        "  shipments = scenario.shipments\n",
        "\n",
        "  overlaps_by_parking = collections.defaultdict(list)\n",
        "  for overlap in party_stats.overlapping_visits:\n",
        "    overlaps_by_parking[overlap.parking_tag].append(overlap)\n",
        "\n",
        "  for parking_tag in sorted(scenario.parking_locations):\n",
        "    shipments_for_parking = scenario.shipments_for_parking.get(parking_tag, ())\n",
        "    parking_vehicles = parking_data.vehicles_by_parking.get(parking_tag, ())\n",
        "    skipped_shipments_for_parking = set(\n",
        "        shipment_index\n",
        "        for shipment_index in shipments_for_parking\n",
        "        if shipment_index in scenario.skipped_shipment_indices\n",
        "    )\n",
        "\n",
        "    num_cfr_shipments = len(shipments_for_parking)\n",
        "    num_actual_shipments = sum(\n",
        "        shipments[shipment].get(\"label\", \"\").count(\",\") + 1\n",
        "        for shipment in shipments_for_parking\n",
        "    )\n",
        "\n",
        "    num_skipped_cfr_shipments = len(skipped_shipments_for_parking)\n",
        "    num_skipped_actual_shipments = sum(\n",
        "        shipments[shipment].get(\"label\", \"\").count(\",\") + 1\n",
        "        for shipment in skipped_shipments_for_parking\n",
        "    )\n",
        "\n",
        "    vehicle_labels = sorted(\n",
        "        scenario.vehicle_label(vehicle_index)\n",
        "        for vehicle_index in parking_vehicles\n",
        "    )\n",
        "\n",
        "    overlaps = overlaps_by_parking.get(parking_tag, [])\n",
        "    overlaps.sort(key=lambda overlap: overlap.start_time)\n",
        "    overlap_parts = []\n",
        "    for overlap in _merge_overlaps(overlaps):\n",
        "      vehicles = \", \".join(\n",
        "          scenario.vehicle_label(vehicle_index)\n",
        "          for vehicle_index in overlap.vehicles\n",
        "      )\n",
        "      overlap_parts.append(\n",
        "          f\"{overlap.start_time} - {overlap.end_time}: {vehicles}\"\n",
        "      )\n",
        "\n",
        "    data.append({\n",
        "        \"parking_tag\": parking_tag,\n",
        "        \"# visits\": parking_data.num_visits_to_parking[parking_tag],\n",
        "        \"# CFR shipments\": num_cfr_shipments,\n",
        "        \"# actual shipments\": num_actual_shipments,\n",
        "        \"# skipped CFR shipments\": num_skipped_cfr_shipments,\n",
        "        \"# skipped actual shipments\": num_skipped_actual_shipments,\n",
        "        \"# vehicles\": len(parking_vehicles),\n",
        "        \"vehicles\": \", \".join(vehicle_labels),\n",
        "        \"overlaps\": \" | \".join(overlap_parts),\n",
        "    })\n",
        "  return data\n",
        "\n",
        "\n",
        "show_table_from_all_scenarios(get_parking_location_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d08iR0muoPMM"
      },
      "outputs": [],
      "source": [
        "# @title Shipments delivered from a parking location\n",
        "\n",
        "\n",
        "def _shipment_row(scenario, shipment_index):\n",
        "  shipment = scenario.shipments[shipment_index]\n",
        "  time_windows = []\n",
        "  for delivery in shipment.get(\"deliveries\", ()):\n",
        "    time_windows.extend(delivery.get(\"timeWindows\", ()))\n",
        "  vehicle_label = (\n",
        "      \"\"\n",
        "      if shipment_index in scenario.skipped_shipment_indices\n",
        "      else scenario.vehicle_label(scenario.vehicle_for_shipment[shipment_index])\n",
        "  )\n",
        "  shipment_row = {\n",
        "      \"label\": shipment.get(\"label\", \"\"),\n",
        "      \"allowed vehicles\": \", \".join(\n",
        "          str(vehicle) for vehicle in shipment.get(\"allowedVehicleIndices\", ())\n",
        "      ),\n",
        "      \"delivery time window\": human_readable.time_windows(time_windows),\n",
        "      \"used vehicle\": vehicle_label,\n",
        "  }\n",
        "  return shipment_row\n",
        "\n",
        "\n",
        "def create_shipments_delivered_from_parking_location_ui():\n",
        "  scenario_selector = ipywidgets.Dropdown(description=\"Scenario:\", options=[])\n",
        "  parking_selector = ipywidgets.Dropdown(description=\"Parking tag:\", options=[])\n",
        "  refresh_button = ipywidgets.Button(description=\"Refresh\")\n",
        "\n",
        "  display.display(\n",
        "      ipywidgets.HBox(\n",
        "          children=[scenario_selector, parking_selector, refresh_button]\n",
        "      )\n",
        "  )\n",
        "\n",
        "  scenario = None\n",
        "  parking_data = None\n",
        "\n",
        "  def on_scenario_selected(_):\n",
        "    nonlocal scenario\n",
        "    nonlocal parking_data\n",
        "    scenario = _scenarios[scenario_selector.value]\n",
        "    parking_data = scenario.parking_location_data\n",
        "    parking_selector.options = sorted(parking_data.all_parking_tags)\n",
        "\n",
        "  scenario_selector.observe(on_scenario_selected, names=[\"value\"])\n",
        "  scenario_selector.options = _scenarios.keys()\n",
        "\n",
        "  def on_refresh(_):\n",
        "    parking_tag = parking_selector.value\n",
        "    shipments = scenario.shipments\n",
        "    vehicles = scenario.vehicles\n",
        "\n",
        "    shipment_data = []\n",
        "    for group_index, shipment_group in enumerate(\n",
        "        parking_data.shipments_by_parking[parking_tag]\n",
        "    ):\n",
        "      for index_in_group, shipment_index in enumerate(shipment_group):\n",
        "        row = {\"index in group\": index_in_group, \"group\": group_index}\n",
        "        row.update(_shipment_row(scenario, shipment_index))\n",
        "        shipment_data.append(row)\n",
        "\n",
        "    for shipment_index in scenario.shipments_for_parking[parking_tag]:\n",
        "      if shipment_index not in scenario.skipped_shipment_indices:\n",
        "        continue\n",
        "      row = {\"index in group\": \"\", \"group\": \"\"}\n",
        "      row.update(_shipment_row(scenario, shipment_index))\n",
        "      shipment_data.append(row)\n",
        "\n",
        "    output.clear(output_tags=[\"table_container\"])\n",
        "    with output.use_tags(\"table_container\", append=True):\n",
        "      display.display(data_table.DataTable(pd.DataFrame(shipment_data)))\n",
        "\n",
        "  refresh_button.on_click(on_refresh)\n",
        "\n",
        "\n",
        "create_shipments_delivered_from_parking_location_ui()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "q7PVQWUsf3iF"
      ],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "CFR JSON request/response analysis",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
